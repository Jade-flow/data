{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "ch7_programming_Colab_notebook.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remjw/data/blob/master/notebook/calculate-stats-list.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 7 Programming Homework Starter Program"
      ],
      "metadata": {
        "id": "xwJC3oQaNM9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, execute Cell 1 to load dependencies, download data and create user-defined functions"
      ],
      "metadata": {
        "id": "ty0Ru0a6NV5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 1\n",
        "import csv\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def download_to_file(url, to_file):\n",
        "    '''download file by url,save file'''\n",
        "    # Download from URL\n",
        "    with urlopen(url) as f:\n",
        "        content = f.read().decode('utf-8', 'ignore')\n",
        "    # Save to file\n",
        "    with open(to_file, 'w') as download:\n",
        "        download.write(content)\n",
        "    return f'You can find the data download in {to_file}.'\n"
      ],
      "metadata": {
        "id": "TCIgbRDg7wt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You work in this cell to\n",
        "\n",
        "- Complete `analyze_base_python(entries)`\n",
        "\n",
        "- Only use Python Base in the function `analyze_base_python` to perform the same analysis and display the expected output.\n",
        "\n",
        "- Run the cell to display the analysis result."
      ],
      "metadata": {
        "id": "V07onf7qNv4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 2\n",
        "def analyze_base_python(entries):\n",
        "    '''to-be-completed, only use Python base library\n",
        "    analyze entries to answer the questions'''\n",
        "\n",
        "    # inspect first tuple values in a record\n",
        "    print(f'first entry: {entries[0]}')\n",
        "\n",
        "    report = f'The program only uses Python Base.\\n'\n",
        "\n",
        "    avg_num_comments = 0\n",
        "    avg_score = 0\n",
        "    # highest score\n",
        "    max_score = 0\n",
        "    top_post_title_by_score = None\n",
        "    # lowest score\n",
        "    min_score = 0\n",
        "    last_post_title_by_score = None\n",
        "    # most commented\n",
        "    max_comms = 0\n",
        "    most_commented_post_title = None\n",
        "\n",
        "    # -------\n",
        "    # write code to calculate the values above\n",
        "    # --------\n",
        "\n",
        "    report += f'\\nAverage number of comments per post: {avg_num_comments:15,.3f}'\n",
        "    report += f'\\nAverage score per post: {avg_score:15,.3f}'\n",
        "    report += f'\\nTop Post title (score {max_score:.3f}): {top_post_title_by_score}'\n",
        "    report += f'\\nLast Post title (score {min_score:.3f}): {last_post_title_by_score}'\n",
        "    report += f'\\nMost Commented title ({max_comms} comments): {most_commented_post_title}'\n",
        "    return report\n",
        "\n",
        "\n",
        "def main():\n",
        "    # download data, then save to csv file\n",
        "    url = \"https://raw.githubusercontent.com/remjw/data/master/py_programming_data/reddit_vm.csv\"\n",
        "    print(download_to_file(url, \"reddit_vm.csv\"))\n",
        "\n",
        "    # read csv into a tuple list\n",
        "    with open(\"reddit_vm.csv\", \"r\", encoding='UTF-8', errors=\"ignore\") as f:\n",
        "        # read data into a list of tuples\n",
        "        entries = [\n",
        "            (e['id'], int(e['score']), int(e['comms_num']), e['title'])\n",
        "            for e in csv.DictReader(f)\n",
        "        ]\n",
        "    # print(entries)\n",
        "\n",
        "    print(analyze_base_python(entries))\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBDde-qu7zEt",
        "outputId": "de225044-2fa5-49b2-ea6d-60157ea9b7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can find the data download in reddit_vm.csv.\n",
            "first entry: ('lt74vw', 7, 0, 'Health Canada approves AstraZeneca COVID-19 vaccine')\n",
            "The program only uses Python Base.\n",
            "\n",
            "Average number of comments per post:           0.000\n",
            "Average score per post:           0.000\n",
            "Top Post title (score 0.000): None\n",
            "Last Post title (score 0.000): None\n",
            "Most Commented title (0 comments): None\n"
          ]
        }
      ]
    }
  ]
}